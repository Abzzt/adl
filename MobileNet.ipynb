{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\adl\\data_proccessing.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_new = pd.concat([df_new, data_entry[data_entry[l]==1][:500]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4620 validated image filenames belonging to 15 classes.\n",
      "Found 1155 validated image filenames belonging to 15 classes.\n",
      "[[[[0.1137255  0.1137255  0.1137255 ]\n",
      "   [0.1137255  0.1137255  0.1137255 ]\n",
      "   [0.10980393 0.10980393 0.10980393]\n",
      "   ...\n",
      "   [0.18823531 0.18823531 0.18823531]\n",
      "   [0.21960786 0.21960786 0.21960786]\n",
      "   [0.33333334 0.33333334 0.33333334]]\n",
      "\n",
      "  [[0.10980393 0.10980393 0.10980393]\n",
      "   [0.1137255  0.1137255  0.1137255 ]\n",
      "   [0.10980393 0.10980393 0.10980393]\n",
      "   ...\n",
      "   [0.18039216 0.18039216 0.18039216]\n",
      "   [0.21568629 0.21568629 0.21568629]\n",
      "   [0.31764707 0.31764707 0.31764707]]\n",
      "\n",
      "  [[0.1137255  0.1137255  0.1137255 ]\n",
      "   [0.10980393 0.10980393 0.10980393]\n",
      "   [0.10980393 0.10980393 0.10980393]\n",
      "   ...\n",
      "   [0.18823531 0.18823531 0.18823531]\n",
      "   [0.21176472 0.21176472 0.21176472]\n",
      "   [0.29803923 0.29803923 0.29803923]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.6901961  0.6901961  0.6901961 ]\n",
      "   [0.6862745  0.6862745  0.6862745 ]\n",
      "   [0.68235296 0.68235296 0.68235296]\n",
      "   ...\n",
      "   [0.13725491 0.13725491 0.13725491]\n",
      "   [0.15294118 0.15294118 0.15294118]\n",
      "   [0.15294118 0.15294118 0.15294118]]\n",
      "\n",
      "  [[0.7176471  0.7176471  0.7176471 ]\n",
      "   [0.70980394 0.70980394 0.70980394]\n",
      "   [0.7019608  0.7019608  0.7019608 ]\n",
      "   ...\n",
      "   [0.1137255  0.1137255  0.1137255 ]\n",
      "   [0.11764707 0.11764707 0.11764707]\n",
      "   [0.12156864 0.12156864 0.12156864]]\n",
      "\n",
      "  [[0.73333335 0.73333335 0.73333335]\n",
      "   [0.73333335 0.73333335 0.73333335]\n",
      "   [0.72156864 0.72156864 0.72156864]\n",
      "   ...\n",
      "   [0.10980393 0.10980393 0.10980393]\n",
      "   [0.10980393 0.10980393 0.10980393]\n",
      "   [0.1254902  0.1254902  0.1254902 ]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.05882353 0.05882353 0.05882353]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.03921569 0.03921569 0.03921569]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.03529412 0.03529412 0.03529412]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.01176471 0.01176471 0.01176471]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.02745098 0.02745098 0.02745098]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.04313726 0.04313726 0.04313726]]]\n",
      "\n",
      "\n",
      " [[[0.09803922 0.09803922 0.09803922]\n",
      "   [0.03921569 0.03921569 0.03921569]\n",
      "   [0.03529412 0.03529412 0.03529412]\n",
      "   ...\n",
      "   [0.04705883 0.04705883 0.04705883]\n",
      "   [0.04705883 0.04705883 0.04705883]\n",
      "   [0.04705883 0.04705883 0.04705883]]\n",
      "\n",
      "  [[0.03921569 0.03921569 0.03921569]\n",
      "   [0.03529412 0.03529412 0.03529412]\n",
      "   [0.03529412 0.03529412 0.03529412]\n",
      "   ...\n",
      "   [0.04313726 0.04313726 0.04313726]\n",
      "   [0.03921569 0.03921569 0.03921569]\n",
      "   [0.03921569 0.03921569 0.03921569]]\n",
      "\n",
      "  [[0.03529412 0.03529412 0.03529412]\n",
      "   [0.03529412 0.03529412 0.03529412]\n",
      "   [0.03137255 0.03137255 0.03137255]\n",
      "   ...\n",
      "   [0.03921569 0.03921569 0.03921569]\n",
      "   [0.03921569 0.03921569 0.03921569]\n",
      "   [0.03529412 0.03529412 0.03529412]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7725491  0.7725491  0.7725491 ]\n",
      "   [0.77647066 0.77647066 0.77647066]\n",
      "   [0.77647066 0.77647066 0.77647066]\n",
      "   ...\n",
      "   [0.6039216  0.6039216  0.6039216 ]\n",
      "   [0.627451   0.627451   0.627451  ]\n",
      "   [0.68235296 0.68235296 0.68235296]]\n",
      "\n",
      "  [[0.76470596 0.76470596 0.76470596]\n",
      "   [0.76470596 0.76470596 0.76470596]\n",
      "   [0.7686275  0.7686275  0.7686275 ]\n",
      "   ...\n",
      "   [0.5647059  0.5647059  0.5647059 ]\n",
      "   [0.63529414 0.63529414 0.63529414]\n",
      "   [0.6627451  0.6627451  0.6627451 ]]\n",
      "\n",
      "  [[0.7803922  0.7803922  0.7803922 ]\n",
      "   [0.7725491  0.7725491  0.7725491 ]\n",
      "   [0.7725491  0.7725491  0.7725491 ]\n",
      "   ...\n",
      "   [0.5372549  0.5372549  0.5372549 ]\n",
      "   [0.6431373  0.6431373  0.6431373 ]\n",
      "   [0.7058824  0.7058824  0.7058824 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.40784317 0.40784317 0.40784317]\n",
      "   [0.26666668 0.26666668 0.26666668]\n",
      "   [0.17254902 0.17254902 0.17254902]\n",
      "   ...\n",
      "   [0.3647059  0.3647059  0.3647059 ]\n",
      "   [0.454902   0.454902   0.454902  ]\n",
      "   [0.5058824  0.5058824  0.5058824 ]]\n",
      "\n",
      "  [[0.16470589 0.16470589 0.16470589]\n",
      "   [0.06666667 0.06666667 0.06666667]\n",
      "   [0.01960784 0.01960784 0.01960784]\n",
      "   ...\n",
      "   [0.04313726 0.04313726 0.04313726]\n",
      "   [0.09803922 0.09803922 0.09803922]\n",
      "   [0.16470589 0.16470589 0.16470589]]\n",
      "\n",
      "  [[0.01568628 0.01568628 0.01568628]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.8745099  0.8745099  0.8745099 ]\n",
      "   [0.8745099  0.8745099  0.8745099 ]\n",
      "   [0.86666673 0.86666673 0.86666673]\n",
      "   ...\n",
      "   [0.0627451  0.0627451  0.0627451 ]\n",
      "   [0.0627451  0.0627451  0.0627451 ]\n",
      "   [0.06666667 0.06666667 0.06666667]]\n",
      "\n",
      "  [[0.8745099  0.8745099  0.8745099 ]\n",
      "   [0.8745099  0.8745099  0.8745099 ]\n",
      "   [0.8705883  0.8705883  0.8705883 ]\n",
      "   ...\n",
      "   [0.05490196 0.05490196 0.05490196]\n",
      "   [0.0627451  0.0627451  0.0627451 ]\n",
      "   [0.0627451  0.0627451  0.0627451 ]]\n",
      "\n",
      "  [[0.86666673 0.86666673 0.86666673]\n",
      "   [0.86666673 0.86666673 0.86666673]\n",
      "   [0.86274517 0.86274517 0.86274517]\n",
      "   ...\n",
      "   [0.18039216 0.18039216 0.18039216]\n",
      "   [0.0627451  0.0627451  0.0627451 ]\n",
      "   [0.0627451  0.0627451  0.0627451 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.9333334  0.9333334  0.9333334 ]\n",
      "   [0.92549026 0.92549026 0.92549026]\n",
      "   [0.93725497 0.93725497 0.93725497]\n",
      "   ...\n",
      "   [0.36862746 0.36862746 0.36862746]\n",
      "   [0.39607847 0.39607847 0.39607847]\n",
      "   [0.43529415 0.43529415 0.43529415]]\n",
      "\n",
      "  [[0.9333334  0.9333334  0.9333334 ]\n",
      "   [0.92549026 0.92549026 0.92549026]\n",
      "   [0.9333334  0.9333334  0.9333334 ]\n",
      "   ...\n",
      "   [0.36862746 0.36862746 0.36862746]\n",
      "   [0.4039216  0.4039216  0.4039216 ]\n",
      "   [0.42352945 0.42352945 0.42352945]]\n",
      "\n",
      "  [[0.92549026 0.92549026 0.92549026]\n",
      "   [0.9215687  0.9215687  0.9215687 ]\n",
      "   [0.9294118  0.9294118  0.9294118 ]\n",
      "   ...\n",
      "   [0.36862746 0.36862746 0.36862746]\n",
      "   [0.38823533 0.38823533 0.38823533]\n",
      "   [0.4156863  0.4156863  0.4156863 ]]]\n",
      "\n",
      "\n",
      " [[[0.87843144 0.87843144 0.87843144]\n",
      "   [0.8470589  0.8470589  0.8470589 ]\n",
      "   [0.6431373  0.6431373  0.6431373 ]\n",
      "   ...\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   [0.09019608 0.09019608 0.09019608]\n",
      "   [0.09411766 0.09411766 0.09411766]]\n",
      "\n",
      "  [[0.7960785  0.7960785  0.7960785 ]\n",
      "   [0.6039216  0.6039216  0.6039216 ]\n",
      "   [0.34901962 0.34901962 0.34901962]\n",
      "   ...\n",
      "   [0.01568628 0.01568628 0.01568628]\n",
      "   [0.01568628 0.01568628 0.01568628]\n",
      "   [0.01960784 0.01960784 0.01960784]]\n",
      "\n",
      "  [[0.46274513 0.46274513 0.46274513]\n",
      "   [0.2627451  0.2627451  0.2627451 ]\n",
      "   [0.09411766 0.09411766 0.09411766]\n",
      "   ...\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.24313727 0.24313727 0.24313727]\n",
      "   [0.10588236 0.10588236 0.10588236]\n",
      "   [0.03137255 0.03137255 0.03137255]\n",
      "   ...\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.00784314 0.00784314 0.00784314]]\n",
      "\n",
      "  [[0.24705884 0.24705884 0.24705884]\n",
      "   [0.1254902  0.1254902  0.1254902 ]\n",
      "   [0.04313726 0.04313726 0.04313726]\n",
      "   ...\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.01176471 0.01176471 0.01176471]\n",
      "   [0.01176471 0.01176471 0.01176471]]\n",
      "\n",
      "  [[0.25882354 0.25882354 0.25882354]\n",
      "   [0.14117648 0.14117648 0.14117648]\n",
      "   [0.05882353 0.05882353 0.05882353]\n",
      "   ...\n",
      "   [0.01176471 0.01176471 0.01176471]\n",
      "   [0.01176471 0.01176471 0.01176471]\n",
      "   [0.01568628 0.01568628 0.01568628]]]] [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "\u001b[1m17225924/17225924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNet\n",
    "import tensorflow as tf\n",
    "from data_proccessing import image_size, labels\n",
    "\n",
    "mnet = MobileNet(\n",
    "        input_shape=(image_size, image_size, 3),\n",
    "        weights='imagenet',\n",
    "        include_top=False\n",
    "    )\n",
    "mnet.trainable = True\n",
    "\n",
    "mnet_model = tf.keras.Sequential([\n",
    "    mnet,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(len(labels), activation='sigmoid')])\n",
    "\n",
    "mnet_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics=['AUC','Precision','Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mandi\\anaconda3\\envs\\adl\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 2s/step - AUC: 0.6297 - Precision: 0.2203 - Recall: 0.0608 - loss: 0.3739 - val_AUC: 0.5732 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_loss: 0.8864\n",
      "Epoch 2/10\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 2s/step - AUC: 0.7285 - Precision: 0.5110 - Recall: 0.0637 - loss: 0.3122 - val_AUC: 0.6570 - val_Precision: 0.2685 - val_Recall: 0.0357 - val_loss: 0.4120\n",
      "Epoch 3/10\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 2s/step - AUC: 0.7561 - Precision: 0.5485 - Recall: 0.0808 - loss: 0.3032 - val_AUC: 0.6674 - val_Precision: 0.6154 - val_Recall: 0.0041 - val_loss: 0.4018\n",
      "Epoch 4/10\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 2s/step - AUC: 0.7730 - Precision: 0.5487 - Recall: 0.0954 - loss: 0.2969 - val_AUC: 0.6722 - val_Precision: 0.4348 - val_Recall: 0.0052 - val_loss: 0.4040\n",
      "Epoch 5/10\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 2s/step - AUC: 0.7864 - Precision: 0.5692 - Recall: 0.0996 - loss: 0.2909 - val_AUC: 0.7084 - val_Precision: 0.4249 - val_Recall: 0.0953 - val_loss: 0.3306\n",
      "Epoch 6/10\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 2s/step - AUC: 0.7982 - Precision: 0.6235 - Recall: 0.1390 - loss: 0.2855 - val_AUC: 0.7145 - val_Precision: 0.4509 - val_Recall: 0.0642 - val_loss: 0.3393\n",
      "Epoch 7/10\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 2s/step - AUC: 0.8057 - Precision: 0.6233 - Recall: 0.1573 - loss: 0.2821 - val_AUC: 0.7269 - val_Precision: 0.4754 - val_Recall: 0.0601 - val_loss: 0.3267\n",
      "Epoch 8/10\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 2s/step - AUC: 0.8194 - Precision: 0.6479 - Recall: 0.1656 - loss: 0.2714 - val_AUC: 0.6562 - val_Precision: 0.1593 - val_Recall: 0.0844 - val_loss: 0.4576\n",
      "Epoch 9/10\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 2s/step - AUC: 0.8240 - Precision: 0.6267 - Recall: 0.1631 - loss: 0.2697 - val_AUC: 0.6866 - val_Precision: 0.5092 - val_Recall: 0.0430 - val_loss: 0.3454\n",
      "Epoch 10/10\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 2s/step - AUC: 0.8243 - Precision: 0.6523 - Recall: 0.1753 - loss: 0.2692 - val_AUC: 0.6986 - val_Precision: 0.2653 - val_Recall: 0.1662 - val_loss: 0.3749\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 298ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, average_precision_score\n",
    "from data_proccessing import train_gen, valid_gen, X_val, y_val\n",
    "\n",
    "history = mnet_model.fit(train_gen,\n",
    "              validation_data = valid_gen,\n",
    "              epochs = 10,)\n",
    "\n",
    "y_pred = mnet_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atelectasis: actual: 16.54%, predicted: 20.60%\n",
      "Cardiomegaly: actual: 9.09%, predicted: 0.97%\n",
      "Consolidation: actual: 9.78%, predicted: 48.25%\n",
      "Edema: actual: 9.44%, predicted: 4.86%\n",
      "Effusion: actual: 17.66%, predicted: 22.79%\n",
      "Emphysema: actual: 9.09%, predicted: 4.13%\n",
      "Fibrosis: actual: 8.92%, predicted: 1.61%\n",
      "Hernia: actual: 3.98%, predicted: 0.58%\n",
      "Infiltration: actual: 25.54%, predicted: 43.22%\n",
      "Mass: actual: 9.96%, predicted: 4.40%\n",
      "No Finding: actual: 8.66%, predicted: 3.93%\n",
      "Nodule: actual: 10.39%, predicted: 3.42%\n",
      "Pleural_Thickening: actual: 8.40%, predicted: 3.35%\n",
      "Pneumonia: actual: 8.92%, predicted: 10.86%\n",
      "Pneumothorax: actual: 10.82%, predicted: 8.08%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for label, p_count, t_count in zip(labels,\n",
    "                                     100 * np.mean(y_pred, 0),\n",
    "                                     100 * np.mean(y_val, 0)):\n",
    "    print('%s: actual: %2.2f%%, predicted: %2.2f%%' % (label, t_count, p_count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
