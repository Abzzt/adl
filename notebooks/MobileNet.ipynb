{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\adl\\data_proccessing.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_new = pd.concat([df_new, data_entry[data_entry[l]==1][:500]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4620 validated image filenames belonging to 15 classes.\n",
      "Found 1155 validated image filenames belonging to 15 classes.\n",
      "[[[[0.14117648 0.14117648 0.14117648]\n",
      "   [0.13725491 0.13725491 0.13725491]\n",
      "   [0.12941177 0.12941177 0.12941177]\n",
      "   ...\n",
      "   [0.12941177 0.12941177 0.12941177]\n",
      "   [0.16078432 0.16078432 0.16078432]\n",
      "   [0.20392159 0.20392159 0.20392159]]\n",
      "\n",
      "  [[0.13333334 0.13333334 0.13333334]\n",
      "   [0.13333334 0.13333334 0.13333334]\n",
      "   [0.12941177 0.12941177 0.12941177]\n",
      "   ...\n",
      "   [0.12156864 0.12156864 0.12156864]\n",
      "   [0.14901961 0.14901961 0.14901961]\n",
      "   [0.19607845 0.19607845 0.19607845]]\n",
      "\n",
      "  [[0.13333334 0.13333334 0.13333334]\n",
      "   [0.13333334 0.13333334 0.13333334]\n",
      "   [0.1254902  0.1254902  0.1254902 ]\n",
      "   ...\n",
      "   [0.11764707 0.11764707 0.11764707]\n",
      "   [0.15294118 0.15294118 0.15294118]\n",
      "   [0.18823531 0.18823531 0.18823531]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.6666667  0.6666667  0.6666667 ]\n",
      "   [0.7058824  0.7058824  0.7058824 ]\n",
      "   [0.7058824  0.7058824  0.7058824 ]\n",
      "   ...\n",
      "   [0.16078432 0.16078432 0.16078432]\n",
      "   [0.21176472 0.21176472 0.21176472]\n",
      "   [0.27058825 0.27058825 0.27058825]]\n",
      "\n",
      "  [[0.6862745  0.6862745  0.6862745 ]\n",
      "   [0.70980394 0.70980394 0.70980394]\n",
      "   [0.73333335 0.73333335 0.73333335]\n",
      "   ...\n",
      "   [0.16078432 0.16078432 0.16078432]\n",
      "   [0.21176472 0.21176472 0.21176472]\n",
      "   [0.26666668 0.26666668 0.26666668]]\n",
      "\n",
      "  [[0.70980394 0.70980394 0.70980394]\n",
      "   [0.7176471  0.7176471  0.7176471 ]\n",
      "   [0.73333335 0.73333335 0.73333335]\n",
      "   ...\n",
      "   [0.16470589 0.16470589 0.16470589]\n",
      "   [0.21568629 0.21568629 0.21568629]\n",
      "   [0.27058825 0.27058825 0.27058825]]]\n",
      "\n",
      "\n",
      " [[[0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.13725491 0.13725491 0.13725491]\n",
      "   ...\n",
      "   [0.09019608 0.09019608 0.09019608]\n",
      "   [0.09803922 0.09803922 0.09803922]\n",
      "   [0.10196079 0.10196079 0.10196079]]\n",
      "\n",
      "  [[0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.13333334 0.13333334 0.13333334]\n",
      "   ...\n",
      "   [0.08235294 0.08235294 0.08235294]\n",
      "   [0.07843138 0.07843138 0.07843138]\n",
      "   [0.08235294 0.08235294 0.08235294]]\n",
      "\n",
      "  [[0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.13725491 0.13725491 0.13725491]\n",
      "   ...\n",
      "   [0.07450981 0.07450981 0.07450981]\n",
      "   [0.07058824 0.07058824 0.07058824]\n",
      "   [0.07058824 0.07058824 0.07058824]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.21176472 0.21176472 0.21176472]\n",
      "   ...\n",
      "   [0.96470594 0.96470594 0.96470594]\n",
      "   [0.9607844  0.9607844  0.9607844 ]\n",
      "   [0.96470594 0.96470594 0.96470594]]\n",
      "\n",
      "  [[0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.20000002 0.20000002 0.20000002]\n",
      "   ...\n",
      "   [0.96470594 0.96470594 0.96470594]\n",
      "   [0.96470594 0.96470594 0.96470594]\n",
      "   [0.9450981  0.9450981  0.9450981 ]]\n",
      "\n",
      "  [[0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.25490198 0.25490198 0.25490198]\n",
      "   ...\n",
      "   [0.90196085 0.90196085 0.90196085]\n",
      "   [0.90196085 0.90196085 0.90196085]\n",
      "   [0.91372555 0.91372555 0.91372555]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.4431373  0.4431373  0.4431373 ]\n",
      "   [0.36078432 0.36078432 0.36078432]\n",
      "   [0.3019608  0.3019608  0.3019608 ]\n",
      "   ...\n",
      "   [0.4666667  0.4666667  0.4666667 ]\n",
      "   [0.44705886 0.44705886 0.44705886]\n",
      "   [0.43529415 0.43529415 0.43529415]]\n",
      "\n",
      "  [[0.36078432 0.36078432 0.36078432]\n",
      "   [0.28627452 0.28627452 0.28627452]\n",
      "   [0.22352943 0.22352943 0.22352943]\n",
      "   ...\n",
      "   [0.3137255  0.3137255  0.3137255 ]\n",
      "   [0.33333334 0.33333334 0.33333334]\n",
      "   [0.3019608  0.3019608  0.3019608 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [0.95294124 0.95294124 0.95294124]\n",
      "   [0.9333334  0.9333334  0.9333334 ]\n",
      "   ...\n",
      "   [0.93725497 0.93725497 0.93725497]\n",
      "   [0.93725497 0.93725497 0.93725497]\n",
      "   [0.93725497 0.93725497 0.93725497]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [0.9176471  0.9176471  0.9176471 ]\n",
      "   [0.94117653 0.94117653 0.94117653]\n",
      "   ...\n",
      "   [0.94117653 0.94117653 0.94117653]\n",
      "   [0.93725497 0.93725497 0.93725497]\n",
      "   [0.93725497 0.93725497 0.93725497]]\n",
      "\n",
      "  [[0.9686275  0.9686275  0.9686275 ]\n",
      "   [0.92549026 0.92549026 0.92549026]\n",
      "   [0.9490197  0.9490197  0.9490197 ]\n",
      "   ...\n",
      "   [0.9450981  0.9450981  0.9450981 ]\n",
      "   [0.9490197  0.9490197  0.9490197 ]\n",
      "   [0.94117653 0.94117653 0.94117653]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.7607844  0.7607844  0.7607844 ]\n",
      "   [0.76470596 0.76470596 0.76470596]\n",
      "   [0.75294125 0.75294125 0.75294125]\n",
      "   ...\n",
      "   [0.09803922 0.09803922 0.09803922]\n",
      "   [0.09803922 0.09803922 0.09803922]\n",
      "   [0.10196079 0.10196079 0.10196079]]\n",
      "\n",
      "  [[0.7568628  0.7568628  0.7568628 ]\n",
      "   [0.76470596 0.76470596 0.76470596]\n",
      "   [0.75294125 0.75294125 0.75294125]\n",
      "   ...\n",
      "   [0.09019608 0.09019608 0.09019608]\n",
      "   [0.09411766 0.09411766 0.09411766]\n",
      "   [0.09411766 0.09411766 0.09411766]]\n",
      "\n",
      "  [[0.75294125 0.75294125 0.75294125]\n",
      "   [0.7568628  0.7568628  0.7568628 ]\n",
      "   [0.74509805 0.74509805 0.74509805]\n",
      "   ...\n",
      "   [0.08235294 0.08235294 0.08235294]\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   [0.09803922 0.09803922 0.09803922]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.6666667  0.6666667  0.6666667 ]\n",
      "   [0.5294118  0.5294118  0.5294118 ]\n",
      "   [0.38823533 0.38823533 0.38823533]\n",
      "   ...\n",
      "   [0.12941177 0.12941177 0.12941177]\n",
      "   [0.04705883 0.04705883 0.04705883]\n",
      "   [0.05490196 0.05490196 0.05490196]]\n",
      "\n",
      "  [[0.7568628  0.7568628  0.7568628 ]\n",
      "   [0.6745098  0.6745098  0.6745098 ]\n",
      "   [0.5568628  0.5568628  0.5568628 ]\n",
      "   ...\n",
      "   [0.14117648 0.14117648 0.14117648]\n",
      "   [0.05882353 0.05882353 0.05882353]\n",
      "   [0.06666667 0.06666667 0.06666667]]\n",
      "\n",
      "  [[0.8078432  0.8078432  0.8078432 ]\n",
      "   [0.7686275  0.7686275  0.7686275 ]\n",
      "   [0.7137255  0.7137255  0.7137255 ]\n",
      "   ...\n",
      "   [0.15294118 0.15294118 0.15294118]\n",
      "   [0.07843138 0.07843138 0.07843138]\n",
      "   [0.07843138 0.07843138 0.07843138]]]\n",
      "\n",
      "\n",
      " [[[0.06666667 0.06666667 0.06666667]\n",
      "   [0.06666667 0.06666667 0.06666667]\n",
      "   [0.06666667 0.06666667 0.06666667]\n",
      "   ...\n",
      "   [0.06666667 0.06666667 0.06666667]\n",
      "   [0.20392159 0.20392159 0.20392159]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.06666667 0.06666667 0.06666667]\n",
      "   [0.06666667 0.06666667 0.06666667]\n",
      "   [0.06666667 0.06666667 0.06666667]\n",
      "   ...\n",
      "   [0.0627451  0.0627451  0.0627451 ]\n",
      "   [0.19215688 0.19215688 0.19215688]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.06666667 0.06666667 0.06666667]\n",
      "   [0.0627451  0.0627451  0.0627451 ]\n",
      "   [0.0627451  0.0627451  0.0627451 ]\n",
      "   ...\n",
      "   [0.06666667 0.06666667 0.06666667]\n",
      "   [0.19607845 0.19607845 0.19607845]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.36078432 0.36078432 0.36078432]\n",
      "   [0.48235297 0.48235297 0.48235297]\n",
      "   [0.57254905 0.57254905 0.57254905]\n",
      "   ...\n",
      "   [0.05490196 0.05490196 0.05490196]\n",
      "   [0.05882353 0.05882353 0.05882353]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.3372549  0.3372549  0.3372549 ]\n",
      "   [0.4666667  0.4666667  0.4666667 ]\n",
      "   [0.5568628  0.5568628  0.5568628 ]\n",
      "   ...\n",
      "   [0.07450981 0.07450981 0.07450981]\n",
      "   [0.05490196 0.05490196 0.05490196]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.30980393 0.30980393 0.30980393]\n",
      "   [0.47058827 0.47058827 0.47058827]\n",
      "   [0.58431375 0.58431375 0.58431375]\n",
      "   ...\n",
      "   [0.08235294 0.08235294 0.08235294]\n",
      "   [0.07843138 0.07843138 0.07843138]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.03921569 0.03921569 0.03921569]\n",
      "   [0.03921569 0.03921569 0.03921569]\n",
      "   [0.03921569 0.03921569 0.03921569]\n",
      "   ...\n",
      "   [0.03921569 0.03921569 0.03921569]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   [0.07058824 0.07058824 0.07058824]]\n",
      "\n",
      "  [[0.04313726 0.04313726 0.04313726]\n",
      "   [0.03921569 0.03921569 0.03921569]\n",
      "   [0.03921569 0.03921569 0.03921569]\n",
      "   ...\n",
      "   [0.03921569 0.03921569 0.03921569]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   [0.07058824 0.07058824 0.07058824]]\n",
      "\n",
      "  [[0.03921569 0.03921569 0.03921569]\n",
      "   [0.03921569 0.03921569 0.03921569]\n",
      "   [0.03921569 0.03921569 0.03921569]\n",
      "   ...\n",
      "   [0.03529412 0.03529412 0.03529412]\n",
      "   [0.04705883 0.04705883 0.04705883]\n",
      "   [0.06666667 0.06666667 0.06666667]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.8980393  0.8980393  0.8980393 ]\n",
      "   [0.8980393  0.8980393  0.8980393 ]\n",
      "   [0.90196085 0.90196085 0.90196085]\n",
      "   ...\n",
      "   [0.8352942  0.8352942  0.8352942 ]\n",
      "   [0.854902   0.854902   0.854902  ]\n",
      "   [0.8705883  0.8705883  0.8705883 ]]\n",
      "\n",
      "  [[0.8980393  0.8980393  0.8980393 ]\n",
      "   [0.9058824  0.9058824  0.9058824 ]\n",
      "   [0.909804   0.909804   0.909804  ]\n",
      "   ...\n",
      "   [0.8431373  0.8431373  0.8431373 ]\n",
      "   [0.8588236  0.8588236  0.8588236 ]\n",
      "   [0.8745099  0.8745099  0.8745099 ]]\n",
      "\n",
      "  [[0.909804   0.909804   0.909804  ]\n",
      "   [0.909804   0.909804   0.909804  ]\n",
      "   [0.909804   0.909804   0.909804  ]\n",
      "   ...\n",
      "   [0.85098046 0.85098046 0.85098046]\n",
      "   [0.86274517 0.86274517 0.86274517]\n",
      "   [0.87843144 0.87843144 0.87843144]]]] [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNet\n",
    "import tensorflow as tf\n",
    "from data_proccessing import image_size, labels\n",
    "\n",
    "mnet = MobileNet(\n",
    "        input_shape=(image_size, image_size, 3),\n",
    "        weights='imagenet',\n",
    "        include_top=False\n",
    "    )\n",
    "mnet.trainable = True\n",
    "\n",
    "mnet_model = tf.keras.Sequential([\n",
    "    mnet,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(len(labels), activation='sigmoid')])\n",
    "\n",
    "mnet_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics=['AUC','Precision','Recall', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "145/145 [==============================] - 113s 734ms/step - loss: 0.3440 - auc: 0.6632 - precision: 0.2910 - recall: 0.0487 - Accuracy: 0.1498 - val_loss: 0.9703 - val_auc: 0.5515 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_Accuracy: 0.0978\n",
      "Epoch 2/10\n",
      "145/145 [==============================] - 74s 512ms/step - loss: 0.3115 - auc: 0.7342 - precision: 0.5051 - recall: 0.0644 - Accuracy: 0.2113 - val_loss: 0.4720 - val_auc: 0.6502 - val_precision: 0.3380 - val_recall: 0.0502 - val_Accuracy: 0.0926\n",
      "Epoch 3/10\n",
      "145/145 [==============================] - 84s 577ms/step - loss: 0.3011 - auc: 0.7601 - precision: 0.5589 - recall: 0.0818 - Accuracy: 0.2411 - val_loss: 0.4155 - val_auc: 0.6529 - val_precision: 0.6429 - val_recall: 0.0047 - val_Accuracy: 0.1810\n",
      "Epoch 4/10\n",
      "145/145 [==============================] - 83s 573ms/step - loss: 0.2961 - auc: 0.7736 - precision: 0.5838 - recall: 0.0951 - Accuracy: 0.2615 - val_loss: 0.3665 - val_auc: 0.6982 - val_precision: 0.5000 - val_recall: 0.0047 - val_Accuracy: 0.1524\n",
      "Epoch 5/10\n",
      "145/145 [==============================] - 85s 584ms/step - loss: 0.2887 - auc: 0.7897 - precision: 0.5895 - recall: 0.1162 - Accuracy: 0.2838 - val_loss: 0.3575 - val_auc: 0.6840 - val_precision: 0.3236 - val_recall: 0.0922 - val_Accuracy: 0.1905\n",
      "Epoch 6/10\n",
      "145/145 [==============================] - 90s 618ms/step - loss: 0.2842 - auc: 0.7973 - precision: 0.6155 - recall: 0.1393 - Accuracy: 0.2920 - val_loss: 0.3155 - val_auc: 0.7303 - val_precision: 0.6081 - val_recall: 0.0233 - val_Accuracy: 0.2000\n",
      "Epoch 7/10\n",
      "145/145 [==============================] - 103s 707ms/step - loss: 0.2785 - auc: 0.8094 - precision: 0.6245 - recall: 0.1502 - Accuracy: 0.3117 - val_loss: 0.3233 - val_auc: 0.7422 - val_precision: 0.5124 - val_recall: 0.0533 - val_Accuracy: 0.2061\n",
      "Epoch 8/10\n",
      "145/145 [==============================] - 83s 574ms/step - loss: 0.2745 - auc: 0.8174 - precision: 0.6182 - recall: 0.1593 - Accuracy: 0.3141 - val_loss: 0.3302 - val_auc: 0.7199 - val_precision: 0.5500 - val_recall: 0.0513 - val_Accuracy: 0.2294\n",
      "Epoch 9/10\n",
      "145/145 [==============================] - 83s 569ms/step - loss: 0.2691 - auc: 0.8260 - precision: 0.6388 - recall: 0.1888 - Accuracy: 0.3359 - val_loss: 0.3361 - val_auc: 0.6875 - val_precision: 0.4404 - val_recall: 0.0249 - val_Accuracy: 0.1957\n",
      "Epoch 10/10\n",
      "145/145 [==============================] - 77s 529ms/step - loss: 0.2634 - auc: 0.8372 - precision: 0.6506 - recall: 0.1911 - Accuracy: 0.3431 - val_loss: 0.3672 - val_auc: 0.6904 - val_precision: 0.2900 - val_recall: 0.1201 - val_Accuracy: 0.1472\n",
      "37/37 [==============================] - 1s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "from data_proccessing import train_gen, valid_gen, X_val, y_val\n",
    "\n",
    "history = mnet_model.fit(train_gen,\n",
    "              validation_data = valid_gen,\n",
    "              epochs = 10,)\n",
    "\n",
    "y_pred = mnet_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atelectasis: actual: 16.54%, predicted: 20.60%\n",
      "Cardiomegaly: actual: 9.09%, predicted: 0.97%\n",
      "Consolidation: actual: 9.78%, predicted: 48.25%\n",
      "Edema: actual: 9.44%, predicted: 4.86%\n",
      "Effusion: actual: 17.66%, predicted: 22.79%\n",
      "Emphysema: actual: 9.09%, predicted: 4.13%\n",
      "Fibrosis: actual: 8.92%, predicted: 1.61%\n",
      "Hernia: actual: 3.98%, predicted: 0.58%\n",
      "Infiltration: actual: 25.54%, predicted: 43.22%\n",
      "Mass: actual: 9.96%, predicted: 4.40%\n",
      "No Finding: actual: 8.66%, predicted: 3.93%\n",
      "Nodule: actual: 10.39%, predicted: 3.42%\n",
      "Pleural_Thickening: actual: 8.40%, predicted: 3.35%\n",
      "Pneumonia: actual: 8.92%, predicted: 10.86%\n",
      "Pneumothorax: actual: 10.82%, predicted: 8.08%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for label, p_count, t_count in zip(labels,\n",
    "                                     100 * np.mean(y_pred, 0),\n",
    "                                     100 * np.mean(y_val, 0)):\n",
    "    print('%s: actual: %2.2f%%, predicted: %2.2f%%' % (label, t_count, p_count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
