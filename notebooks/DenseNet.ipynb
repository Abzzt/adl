{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys  \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "\n",
    "# Define the path to the src directory\n",
    "src_path = os.path.abspath('../src')\n",
    "\n",
    "# Check if the src directory exists\n",
    "if src_path not in sys.path:\n",
    "    # Append src directory to the Python path\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from data_processing import valid_loader, train_loader, test_loader, labels\n",
    "from helper import train, evaluate, test, visualise_all_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(labels)  # Example number of classes\n",
    "\n",
    "torch.manual_seed(43)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DenseNet model\n",
    "dense = models.densenet121(pretrained=True)\n",
    "\n",
    "# Modify the last layer for multi-class classification\n",
    "dense.classifier = nn.Sequential(\n",
    "    nn.Linear(in_features=1024, out_features=len(labels)), # New fully connected layer\n",
    "    nn.Sigmoid() # Add Sigmoid activation\n",
    ")\n",
    "\n",
    "# Freeze the weights of the pre-trained layers\n",
    "for param in dense.parameters():\n",
    "    param.requiresGrad = False\n",
    "\n",
    "# Unfreeze the weights of the last layer\n",
    "for param in dense.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "dense.to(device)\n",
    "\n",
    "# Print the model architecture\n",
    "print(dense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear CUDA memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Paths for saving\n",
    "save_dir = \"../models/densenet_15e/\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Define Params\n",
    "criterion = nn.BCELoss()\n",
    "num_epochs = 15\n",
    "learning_rates = [0.001, 0.0005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track losses for visualization\n",
    "train_losses_dict = {}\n",
    "valid_losses_dict = {}\n",
    "\n",
    "# Iterate over different learning rates\n",
    "for lr in learning_rates:\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, dense.parameters()), lr=lr)\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "    train_losses = []  \n",
    "    valid_losses = []  \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        avg_train_loss = train(dense, train_loader, optimizer, criterion, device)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        valid_loss = evaluate(dense, valid_loader, criterion, device)\n",
    "        valid_losses.append(valid_loss)\n",
    "        \n",
    "        # Print validation loss\n",
    "        print(f'Learning Rate: {lr}, Epoch: {epoch+1}, Train Loss: {avg_train_loss:.4f}, Validation Loss: {valid_loss:.4f}')\n",
    "        \n",
    "        # Save the best model if validation loss improves\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(dense.state_dict(), os.path.join(save_dir, f'best_model_lr_{lr}.pt'))\n",
    "\n",
    "    # Store losses for visualization\n",
    "    train_losses_dict[lr] = train_losses\n",
    "    valid_losses_dict[lr] = valid_losses\n",
    "\n",
    "# Save losses dictionaries for visualization later\n",
    "torch.save(train_losses_dict, os.path.join(save_dir, 'train_losses.pt'))\n",
    "torch.save(valid_losses_dict, os.path.join(save_dir, 'valid_losses.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "for lr in learning_rates:\n",
    "    model_path = os.path.join(save_dir, f'best_model_lr_{lr}.pt')  # Change the filename accordingly\n",
    "    dense.load_state_dict(torch.load(model_path, map_location=torch.device(device)))\n",
    "    metrics, loss = test(dense, test_loader, criterion, device, num_classes)\n",
    "    print(metrics, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Train Loss and Validation Loss on the same graph\n",
    "train_model_path = os.path.join(save_dir, f'train_losses.pt')\n",
    "valid_model_path = os.path.join(save_dir, f'valid_losses.pt')\n",
    "\n",
    "visualise_all_loss(train_model_path, valid_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
