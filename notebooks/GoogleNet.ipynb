{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\adl\\data_proccessing.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_new = pd.concat([df_new, data_entry[data_entry[l]==1][:500]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4620 validated image filenames belonging to 15 classes.\n",
      "Found 1155 validated image filenames belonging to 15 classes.\n",
      "[[[[0.08627451 0.08627451 0.08627451]\n",
      "   [0.07843138 0.07843138 0.07843138]\n",
      "   [0.07843138 0.07843138 0.07843138]\n",
      "   ...\n",
      "   [0.09019608 0.09019608 0.09019608]\n",
      "   [0.10588236 0.10588236 0.10588236]\n",
      "   [0.09803922 0.09803922 0.09803922]]\n",
      "\n",
      "  [[0.08235294 0.08235294 0.08235294]\n",
      "   [0.08235294 0.08235294 0.08235294]\n",
      "   [0.07843138 0.07843138 0.07843138]\n",
      "   ...\n",
      "   [0.09019608 0.09019608 0.09019608]\n",
      "   [0.09411766 0.09411766 0.09411766]\n",
      "   [0.09019608 0.09019608 0.09019608]]\n",
      "\n",
      "  [[0.08235294 0.08235294 0.08235294]\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   [0.08235294 0.08235294 0.08235294]\n",
      "   ...\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   [0.09411766 0.09411766 0.09411766]\n",
      "   [0.09411766 0.09411766 0.09411766]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.60784316 0.60784316 0.60784316]\n",
      "   [0.57254905 0.57254905 0.57254905]\n",
      "   [0.5686275  0.5686275  0.5686275 ]\n",
      "   ...\n",
      "   [0.09803922 0.09803922 0.09803922]\n",
      "   [0.09803922 0.09803922 0.09803922]\n",
      "   [0.12156864 0.12156864 0.12156864]]\n",
      "\n",
      "  [[0.5882353  0.5882353  0.5882353 ]\n",
      "   [0.5568628  0.5568628  0.5568628 ]\n",
      "   [0.5411765  0.5411765  0.5411765 ]\n",
      "   ...\n",
      "   [0.16470589 0.16470589 0.16470589]\n",
      "   [0.3137255  0.3137255  0.3137255 ]\n",
      "   [0.2901961  0.2901961  0.2901961 ]]\n",
      "\n",
      "  [[0.5803922  0.5803922  0.5803922 ]\n",
      "   [0.5529412  0.5529412  0.5529412 ]\n",
      "   [0.5294118  0.5294118  0.5294118 ]\n",
      "   ...\n",
      "   [0.19215688 0.19215688 0.19215688]\n",
      "   [0.16862746 0.16862746 0.16862746]\n",
      "   [0.10980393 0.10980393 0.10980393]]]\n",
      "\n",
      "\n",
      " [[[0.0627451  0.0627451  0.0627451 ]\n",
      "   [0.05882353 0.05882353 0.05882353]\n",
      "   [0.05882353 0.05882353 0.05882353]\n",
      "   ...\n",
      "   [0.05490196 0.05490196 0.05490196]\n",
      "   [0.0627451  0.0627451  0.0627451 ]\n",
      "   [0.0627451  0.0627451  0.0627451 ]]\n",
      "\n",
      "  [[0.04705883 0.04705883 0.04705883]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   [0.04705883 0.04705883 0.04705883]\n",
      "   ...\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   [0.05490196 0.05490196 0.05490196]\n",
      "   [0.0509804  0.0509804  0.0509804 ]]\n",
      "\n",
      "  [[0.03921569 0.03921569 0.03921569]\n",
      "   [0.03921569 0.03921569 0.03921569]\n",
      "   [0.03921569 0.03921569 0.03921569]\n",
      "   ...\n",
      "   [0.03921569 0.03921569 0.03921569]\n",
      "   [0.03921569 0.03921569 0.03921569]\n",
      "   [0.03529412 0.03529412 0.03529412]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.09803922 0.09803922 0.09803922]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   ...\n",
      "   [0.07450981 0.07450981 0.07450981]\n",
      "   [0.08235294 0.08235294 0.08235294]\n",
      "   [0.08235294 0.08235294 0.08235294]]\n",
      "\n",
      "  [[0.0509804  0.0509804  0.0509804 ]\n",
      "   [0.04705883 0.04705883 0.04705883]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   ...\n",
      "   [0.07058824 0.07058824 0.07058824]\n",
      "   [0.07450981 0.07450981 0.07450981]\n",
      "   [0.07843138 0.07843138 0.07843138]]\n",
      "\n",
      "  [[0.0509804  0.0509804  0.0509804 ]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   [0.0509804  0.0509804  0.0509804 ]\n",
      "   ...\n",
      "   [0.07450981 0.07450981 0.07450981]\n",
      "   [0.07450981 0.07450981 0.07450981]\n",
      "   [0.08627451 0.08627451 0.08627451]]]\n",
      "\n",
      "\n",
      " [[[0.01960784 0.01960784 0.01960784]\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   ...\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.00784314 0.00784314 0.00784314]]\n",
      "\n",
      "  [[0.01568628 0.01568628 0.01568628]\n",
      "   [0.01568628 0.01568628 0.01568628]\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   ...\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.00784314 0.00784314 0.00784314]]\n",
      "\n",
      "  [[0.01568628 0.01568628 0.01568628]\n",
      "   [0.01568628 0.01568628 0.01568628]\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   ...\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.00784314 0.00784314 0.00784314]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.06666667 0.06666667 0.06666667]\n",
      "   [0.09019608 0.09019608 0.09019608]\n",
      "   [0.06666667 0.06666667 0.06666667]\n",
      "   ...\n",
      "   [0.02352941 0.02352941 0.02352941]\n",
      "   [0.02352941 0.02352941 0.02352941]\n",
      "   [0.02352941 0.02352941 0.02352941]]\n",
      "\n",
      "  [[0.05882353 0.05882353 0.05882353]\n",
      "   [0.07450981 0.07450981 0.07450981]\n",
      "   [0.08235294 0.08235294 0.08235294]\n",
      "   ...\n",
      "   [0.02352941 0.02352941 0.02352941]\n",
      "   [0.02352941 0.02352941 0.02352941]\n",
      "   [0.02352941 0.02352941 0.02352941]]\n",
      "\n",
      "  [[0.04705883 0.04705883 0.04705883]\n",
      "   [0.05490196 0.05490196 0.05490196]\n",
      "   [0.07058824 0.07058824 0.07058824]\n",
      "   ...\n",
      "   [0.02352941 0.02352941 0.02352941]\n",
      "   [0.02352941 0.02352941 0.02352941]\n",
      "   [0.02352941 0.02352941 0.02352941]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.10980393 0.10980393 0.10980393]\n",
      "   [0.10588236 0.10588236 0.10588236]\n",
      "   [0.10588236 0.10588236 0.10588236]\n",
      "   ...\n",
      "   [0.20000002 0.20000002 0.20000002]\n",
      "   [0.24705884 0.24705884 0.24705884]\n",
      "   [0.29803923 0.29803923 0.29803923]]\n",
      "\n",
      "  [[0.10588236 0.10588236 0.10588236]\n",
      "   [0.10588236 0.10588236 0.10588236]\n",
      "   [0.10588236 0.10588236 0.10588236]\n",
      "   ...\n",
      "   [0.18431373 0.18431373 0.18431373]\n",
      "   [0.16470589 0.16470589 0.16470589]\n",
      "   [0.21568629 0.21568629 0.21568629]]\n",
      "\n",
      "  [[0.10980393 0.10980393 0.10980393]\n",
      "   [0.10196079 0.10196079 0.10196079]\n",
      "   [0.10588236 0.10588236 0.10588236]\n",
      "   ...\n",
      "   [0.2392157  0.2392157  0.2392157 ]\n",
      "   [0.18823531 0.18823531 0.18823531]\n",
      "   [0.26666668 0.26666668 0.26666668]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.18039216 0.18039216 0.18039216]\n",
      "   [0.18823531 0.18823531 0.18823531]\n",
      "   [0.25490198 0.25490198 0.25490198]\n",
      "   ...\n",
      "   [0.17254902 0.17254902 0.17254902]\n",
      "   [0.227451   0.227451   0.227451  ]\n",
      "   [0.25490198 0.25490198 0.25490198]]\n",
      "\n",
      "  [[0.21960786 0.21960786 0.21960786]\n",
      "   [0.32156864 0.32156864 0.32156864]\n",
      "   [0.46274513 0.46274513 0.46274513]\n",
      "   ...\n",
      "   [0.21568629 0.21568629 0.21568629]\n",
      "   [0.2627451  0.2627451  0.2627451 ]\n",
      "   [0.29411766 0.29411766 0.29411766]]\n",
      "\n",
      "  [[0.34509805 0.34509805 0.34509805]\n",
      "   [0.49803925 0.49803925 0.49803925]\n",
      "   [0.54509807 0.54509807 0.54509807]\n",
      "   ...\n",
      "   [0.21176472 0.21176472 0.21176472]\n",
      "   [0.29803923 0.29803923 0.29803923]\n",
      "   [0.36862746 0.36862746 0.36862746]]]\n",
      "\n",
      "\n",
      " [[[0.11764707 0.11764707 0.11764707]\n",
      "   [0.02352941 0.02352941 0.02352941]\n",
      "   [0.01568628 0.01568628 0.01568628]\n",
      "   ...\n",
      "   [0.02352941 0.02352941 0.02352941]\n",
      "   [0.03137255 0.03137255 0.03137255]\n",
      "   [0.02352941 0.02352941 0.02352941]]\n",
      "\n",
      "  [[0.11764707 0.11764707 0.11764707]\n",
      "   [0.02352941 0.02352941 0.02352941]\n",
      "   [0.01568628 0.01568628 0.01568628]\n",
      "   ...\n",
      "   [0.02352941 0.02352941 0.02352941]\n",
      "   [0.02352941 0.02352941 0.02352941]\n",
      "   [0.01960784 0.01960784 0.01960784]]\n",
      "\n",
      "  [[0.13725491 0.13725491 0.13725491]\n",
      "   [0.02745098 0.02745098 0.02745098]\n",
      "   [0.01568628 0.01568628 0.01568628]\n",
      "   ...\n",
      "   [0.02352941 0.02352941 0.02352941]\n",
      "   [0.02352941 0.02352941 0.02352941]\n",
      "   [0.01960784 0.01960784 0.01960784]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.67058825 0.67058825 0.67058825]\n",
      "   [0.6627451  0.6627451  0.6627451 ]\n",
      "   [0.67058825 0.67058825 0.67058825]\n",
      "   ...\n",
      "   [0.02745098 0.02745098 0.02745098]\n",
      "   [0.03137255 0.03137255 0.03137255]\n",
      "   [0.03137255 0.03137255 0.03137255]]\n",
      "\n",
      "  [[0.6627451  0.6627451  0.6627451 ]\n",
      "   [0.6627451  0.6627451  0.6627451 ]\n",
      "   [0.6745098  0.6745098  0.6745098 ]\n",
      "   ...\n",
      "   [0.02745098 0.02745098 0.02745098]\n",
      "   [0.03137255 0.03137255 0.03137255]\n",
      "   [0.03137255 0.03137255 0.03137255]]\n",
      "\n",
      "  [[0.65882355 0.65882355 0.65882355]\n",
      "   [0.6666667  0.6666667  0.6666667 ]\n",
      "   [0.6745098  0.6745098  0.6745098 ]\n",
      "   ...\n",
      "   [0.02745098 0.02745098 0.02745098]\n",
      "   [0.03137255 0.03137255 0.03137255]\n",
      "   [0.03137255 0.03137255 0.03137255]]]\n",
      "\n",
      "\n",
      " [[[0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   ...\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]]\n",
      "\n",
      "  [[0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   ...\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.00392157 0.00392157 0.00392157]]\n",
      "\n",
      "  [[0.07058824 0.07058824 0.07058824]\n",
      "   [0.05490196 0.05490196 0.05490196]\n",
      "   [0.05490196 0.05490196 0.05490196]\n",
      "   ...\n",
      "   [0.08627451 0.08627451 0.08627451]\n",
      "   [0.09411766 0.09411766 0.09411766]\n",
      "   [0.09019608 0.09019608 0.09019608]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.32156864 0.32156864 0.32156864]\n",
      "   [0.28627452 0.28627452 0.28627452]\n",
      "   [0.29411766 0.29411766 0.29411766]\n",
      "   ...\n",
      "   [0.3137255  0.3137255  0.3137255 ]\n",
      "   [0.2392157  0.2392157  0.2392157 ]\n",
      "   [0.1764706  0.1764706  0.1764706 ]]\n",
      "\n",
      "  [[0.31764707 0.31764707 0.31764707]\n",
      "   [0.2784314  0.2784314  0.2784314 ]\n",
      "   [0.30980393 0.30980393 0.30980393]\n",
      "   ...\n",
      "   [0.09803922 0.09803922 0.09803922]\n",
      "   [0.3137255  0.3137255  0.3137255 ]\n",
      "   [0.21176472 0.21176472 0.21176472]]\n",
      "\n",
      "  [[0.30980393 0.30980393 0.30980393]\n",
      "   [0.27058825 0.27058825 0.27058825]\n",
      "   [0.34901962 0.34901962 0.34901962]\n",
      "   ...\n",
      "   [0.07058824 0.07058824 0.07058824]\n",
      "   [0.34901962 0.34901962 0.34901962]\n",
      "   [0.3019608  0.3019608  0.3019608 ]]]] [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from data_proccessing import image_size, labels\n",
    "import tensorflow as tf\n",
    "\n",
    "inception = InceptionV3(\n",
    "    input_shape=(image_size, image_size, 3),\n",
    "    weights='imagenet',\n",
    "    include_top=False\n",
    ")\n",
    "inception.trainable = True\n",
    "\n",
    "inception_model = tf.keras.Sequential([\n",
    "    inception,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(len(labels), activation='sigmoid')\n",
    "])\n",
    "\n",
    "inception_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['AUC','Precision','Recall', 'Accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "145/145 [==============================] - 121s 732ms/step - loss: 0.3418 - auc: 0.6263 - precision: 0.1214 - recall: 0.0050 - Accuracy: 0.0933 - val_loss: 0.4527 - val_auc: 0.6026 - val_precision: 0.2045 - val_recall: 0.0047 - val_Accuracy: 0.0788\n",
      "Epoch 2/10\n",
      "145/145 [==============================] - 78s 540ms/step - loss: 0.3327 - auc: 0.6530 - precision: 0.3667 - recall: 0.0014 - Accuracy: 0.0957 - val_loss: 0.3573 - val_auc: 0.6269 - val_precision: 0.2296 - val_recall: 0.0611 - val_Accuracy: 0.1013\n",
      "Epoch 3/10\n",
      "145/145 [==============================] - 77s 533ms/step - loss: 0.3309 - auc: 0.6590 - precision: 0.4809 - recall: 0.0082 - Accuracy: 0.0998 - val_loss: 0.3371 - val_auc: 0.6476 - val_precision: 0.6000 - val_recall: 0.0031 - val_Accuracy: 0.0900\n",
      "Epoch 4/10\n",
      "145/145 [==============================] - 78s 540ms/step - loss: 0.3294 - auc: 0.6643 - precision: 0.4453 - recall: 0.0074 - Accuracy: 0.1037 - val_loss: 0.3788 - val_auc: 0.5945 - val_precision: 0.1447 - val_recall: 0.0119 - val_Accuracy: 0.0926\n",
      "Epoch 5/10\n",
      "145/145 [==============================] - 80s 551ms/step - loss: 0.3272 - auc: 0.6741 - precision: 0.3675 - recall: 0.0056 - Accuracy: 0.1221 - val_loss: 0.3426 - val_auc: 0.6215 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_Accuracy: 0.1403\n",
      "Epoch 6/10\n",
      "145/145 [==============================] - 78s 540ms/step - loss: 0.3250 - auc: 0.6826 - precision: 0.4628 - recall: 0.0114 - Accuracy: 0.1346 - val_loss: 0.3371 - val_auc: 0.6647 - val_precision: 0.2991 - val_recall: 0.0166 - val_Accuracy: 0.1307\n",
      "Epoch 7/10\n",
      "145/145 [==============================] - 78s 538ms/step - loss: 0.3263 - auc: 0.6784 - precision: 0.4891 - recall: 0.0146 - Accuracy: 0.1305 - val_loss: 0.3802 - val_auc: 0.5685 - val_precision: 0.0433 - val_recall: 0.0057 - val_Accuracy: 0.0874\n",
      "Epoch 8/10\n",
      "145/145 [==============================] - 78s 537ms/step - loss: 0.3236 - auc: 0.6888 - precision: 0.4317 - recall: 0.0128 - Accuracy: 0.1340 - val_loss: 0.3364 - val_auc: 0.6550 - val_precision: 0.1667 - val_recall: 0.0026 - val_Accuracy: 0.1082\n",
      "Epoch 9/10\n",
      "145/145 [==============================] - 77s 533ms/step - loss: 0.3193 - auc: 0.7039 - precision: 0.5238 - recall: 0.0230 - Accuracy: 0.1686 - val_loss: 0.3388 - val_auc: 0.6449 - val_precision: 0.2727 - val_recall: 0.0047 - val_Accuracy: 0.1437\n",
      "Epoch 10/10\n",
      "145/145 [==============================] - 77s 531ms/step - loss: 0.3166 - auc: 0.7125 - precision: 0.5158 - recall: 0.0256 - Accuracy: 0.1714 - val_loss: 0.3656 - val_auc: 0.6119 - val_precision: 0.2457 - val_recall: 0.0440 - val_Accuracy: 0.1056\n",
      "37/37 [==============================] - 3s 63ms/step\n"
     ]
    }
   ],
   "source": [
    "from data_proccessing import train_gen, valid_gen, X_val, y_val\n",
    "\n",
    "history = inception_model.fit(\n",
    "    train_gen,\n",
    "    validation_data=valid_gen,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "y_pred = inception_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atelectasis: actual: 16.54%, predicted: 15.86%\n",
      "Cardiomegaly: actual: 9.09%, predicted: 12.87%\n",
      "Consolidation: actual: 9.78%, predicted: 14.53%\n",
      "Edema: actual: 9.44%, predicted: 24.20%\n",
      "Effusion: actual: 17.66%, predicted: 19.34%\n",
      "Emphysema: actual: 9.09%, predicted: 10.16%\n",
      "Fibrosis: actual: 8.92%, predicted: 3.10%\n",
      "Hernia: actual: 3.98%, predicted: 1.04%\n",
      "Infiltration: actual: 25.54%, predicted: 40.66%\n",
      "Mass: actual: 9.96%, predicted: 9.30%\n",
      "No Finding: actual: 8.66%, predicted: 5.75%\n",
      "Nodule: actual: 10.39%, predicted: 10.35%\n",
      "Pleural_Thickening: actual: 8.40%, predicted: 5.56%\n",
      "Pneumonia: actual: 8.92%, predicted: 10.42%\n",
      "Pneumothorax: actual: 10.82%, predicted: 6.92%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for label, p_count, t_count in zip(labels, 100 * np.mean(y_pred, 0), 100 * np.mean(y_val, 0)):\n",
    "    print('%s: actual: %2.2f%%, predicted: %2.2f%%' % (label, t_count, p_count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
