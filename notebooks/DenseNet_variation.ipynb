{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys  \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the path to the src directory\n",
    "src_path = os.path.abspath('../src')\n",
    "\n",
    "# Check if the src directory exists\n",
    "if src_path not in sys.path:\n",
    "    # Append src directory to the Python path\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from data_processing import valid_loader, train_loader, test_loader, labels\n",
    "from helper import train, evaluate, test, visualise_loss, visualise_all_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(labels)\n",
    "\n",
    "torch.manual_seed(43)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dense Layer\n",
    "class _DenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super(_DenseLayer, self).__init__()\n",
    "        self.norm1 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_channels, growth_rate*4, kernel_size=1, stride=1, bias=False)\n",
    "        self.norm2 = nn.BatchNorm2d(growth_rate*4)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(growth_rate*4, growth_rate, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.classifier = nn.Linear(growth_rate, len(labels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(self.relu1(self.norm1(x)))\n",
    "        out = self.conv2(self.relu2(self.norm2(out)))\n",
    "        out = torch.cat([x, out], 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dense Block\n",
    "class _DenseBlock(nn.Module):\n",
    "    def __init__(self, num_layers, in_channels, growth_rate):\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        self.layers = nn.ModuleList([_DenseLayer(in_channels + i * growth_rate, growth_rate) for i in range(num_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Transition Block\n",
    "class _Transition(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(_Transition, self).__init__()\n",
    "        self.norm = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool(self.conv(self.relu(self.norm(x))))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Custom DenseNet model\n",
    "class CustomDenseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomDenseNet, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False).to(torch.float32)\n",
    "        self.norm0 = nn.BatchNorm2d(64)\n",
    "        self.relu0 = nn.ReLU(inplace=True)\n",
    "        self.pool0 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.denseblock1 = _DenseBlock(num_layers=3, in_channels=64, growth_rate=4)  # Reduced growth rate\n",
    "        self.transition1 = _Transition(in_channels=76, out_channels=128)\n",
    "        self.denseblock2 = _DenseBlock(num_layers=3, in_channels=128, growth_rate=4)  # Added second dense block\n",
    "        self.norm5 = nn.BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  # Adjusted to the output size of the last dense block\n",
    "        self.pool1 = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.linear = nn.Linear(in_features=(140), out_features=15, bias=True)  # Adjusted input features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        x = self.norm0(x)\n",
    "        x = self.relu0(x)\n",
    "        out = self.pool0(x)\n",
    "        out = self.denseblock1(out)\n",
    "        out = self.transition1(out)\n",
    "        out = self.denseblock2(out)\n",
    "        out = F.relu(self.norm5(out))\n",
    "        out = self.pool1(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        out = F.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "# Create an instance of Custom DenseNet\n",
    "custom_densenet = CustomDenseNet()\n",
    "custom_densenet.to(device)\n",
    "\n",
    "# Print the model architecture\n",
    "print(custom_densenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear CUDA memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Paths for saving\n",
    "save_dir = \"../models/densenet_variation_15e/\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Define Params\n",
    "criterion = nn.BCELoss()\n",
    "num_epochs = 15\n",
    "learning_rates = [0.001, 0.0005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track losses for visualization\n",
    "train_losses_dict = {}\n",
    "valid_losses_dict = {}\n",
    "\n",
    "# Iterate over different learning rates\n",
    "for lr in learning_rates:\n",
    "    optimizer = optim.Adam(custom_densenet.parameters(), lr=lr)\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "    train_losses = []  \n",
    "    valid_losses = []  \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        avg_train_loss = train(custom_densenet, train_loader, optimizer, criterion, device)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        valid_loss = evaluate(custom_densenet, valid_loader, criterion, device)\n",
    "        valid_losses.append(valid_loss)\n",
    "        \n",
    "        # Print validation loss\n",
    "        print(f'Learning Rate: {lr}, Epoch: {epoch+1}, Test Loss: {avg_train_loss:.4f}, Validation Loss: {valid_loss:.4f}')\n",
    "        \n",
    "        # Save the best model if validation loss improves\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(custom_densenet.state_dict(), os.path.join(save_dir, f'best_model_lr_{lr}.pt'))\n",
    "\n",
    "    # Store losses for visualization\n",
    "    train_losses_dict[lr] = train_losses\n",
    "    valid_losses_dict[lr] = valid_losses\n",
    "\n",
    "# Save losses dictionaries for visualization later\n",
    "torch.save(train_losses_dict, os.path.join(save_dir, 'train_losses.pt'))\n",
    "torch.save(valid_losses_dict, os.path.join(save_dir, 'valid_losses.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "for lr in learning_rates:\n",
    "    model_path = os.path.join(save_dir, f'best_model_lr_{lr}.pt')  # Change the filename accordingly\n",
    "    custom_densenet.load_state_dict(torch.load(model_path, map_location=torch.device(device)))\n",
    "    metrics, loss = test(custom_densenet, test_loader, criterion, device)\n",
    "    print(metrics, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Train Loss Graph\n",
    "model_path = os.path.join(save_dir, f'train_losses.pt')  # Change the filename accordingly\n",
    "visualise_loss(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Validation Loss Graph\n",
    "model_path = os.path.join(save_dir, f'valid_losses.pt')  # Change the filename accordingly\n",
    "visualise_loss(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Train Loss and Validation Loss on the same graph\n",
    "train_model_path = os.path.join(save_dir, f'train_losses.pt')\n",
    "valid_model_path = os.path.join(save_dir, f'valid_losses.pt')\n",
    "\n",
    "visualise_all_loss(train_model_path, valid_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
