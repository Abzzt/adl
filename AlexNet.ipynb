{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from data_proccessing import  valid_loader,train_loader, labels\n",
    "from helper import train, evaluate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Sequential(\n",
      "      (0): Linear(in_features=4096, out_features=15, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(labels)  # Example number of classes\n",
    "\n",
    "torch.manual_seed(43)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define ResNet model\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "\n",
    "# Modify the last layer for multi-class classification\n",
    "num_features = alexnet.classifier[6].in_features\n",
    "alexnet.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(num_features, num_classes),  # New fully connected layer\n",
    "    nn.Sigmoid()  # Add Sigmoid activation\n",
    ")\n",
    "\n",
    "# Freeze the weights of the pre-trained layers\n",
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the weights of the last layer\n",
    "for param in alexnet.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "alexnet.to(device)\n",
    "\n",
    "# Print the model architecture\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear CUDA memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.001, Epoch: 1, Train Loss: 0.3782, Validation Loss: 0.3758\n",
      "Learning Rate: 0.001, Epoch: 2, Train Loss: 0.3658, Validation Loss: 0.3831\n",
      "Learning Rate: 0.001, Epoch: 3, Train Loss: 0.3618, Validation Loss: 0.3590\n",
      "Learning Rate: 0.001, Epoch: 4, Train Loss: 0.3566, Validation Loss: 0.3547\n",
      "Learning Rate: 0.001, Epoch: 5, Train Loss: 0.3491, Validation Loss: 0.3596\n",
      "Learning Rate: 0.001, Epoch: 6, Train Loss: 0.3440, Validation Loss: 0.3460\n",
      "Learning Rate: 0.001, Epoch: 7, Train Loss: 0.3427, Validation Loss: 0.3579\n",
      "Learning Rate: 0.001, Epoch: 8, Train Loss: 0.3369, Validation Loss: 0.3351\n",
      "Learning Rate: 0.001, Epoch: 9, Train Loss: 0.3356, Validation Loss: 0.3489\n",
      "Learning Rate: 0.001, Epoch: 10, Train Loss: 0.3318, Validation Loss: 0.3322\n",
      "Learning Rate: 0.001, Epoch: 11, Train Loss: 0.3262, Validation Loss: 0.3386\n",
      "Learning Rate: 0.001, Epoch: 12, Train Loss: 0.3217, Validation Loss: 0.3340\n",
      "Learning Rate: 0.001, Epoch: 13, Train Loss: 0.3229, Validation Loss: 0.3436\n",
      "Learning Rate: 0.001, Epoch: 14, Train Loss: 0.3169, Validation Loss: 0.3314\n",
      "Learning Rate: 0.001, Epoch: 15, Train Loss: 0.3132, Validation Loss: 0.3301\n",
      "Learning Rate: 0.0005, Epoch: 1, Train Loss: 0.3040, Validation Loss: 0.3180\n",
      "Learning Rate: 0.0005, Epoch: 2, Train Loss: 0.3007, Validation Loss: 0.3184\n",
      "Learning Rate: 0.0005, Epoch: 3, Train Loss: 0.2949, Validation Loss: 0.3178\n",
      "Learning Rate: 0.0005, Epoch: 4, Train Loss: 0.2948, Validation Loss: 0.3175\n",
      "Learning Rate: 0.0005, Epoch: 5, Train Loss: 0.2913, Validation Loss: 0.3123\n",
      "Learning Rate: 0.0005, Epoch: 6, Train Loss: 0.2880, Validation Loss: 0.3089\n",
      "Learning Rate: 0.0005, Epoch: 7, Train Loss: 0.2851, Validation Loss: 0.3088\n",
      "Learning Rate: 0.0005, Epoch: 8, Train Loss: 0.2868, Validation Loss: 0.3075\n",
      "Learning Rate: 0.0005, Epoch: 9, Train Loss: 0.2840, Validation Loss: 0.3049\n",
      "Learning Rate: 0.0005, Epoch: 10, Train Loss: 0.2838, Validation Loss: 0.3057\n",
      "Learning Rate: 0.0005, Epoch: 11, Train Loss: 0.2782, Validation Loss: 0.3025\n",
      "Learning Rate: 0.0005, Epoch: 12, Train Loss: 0.2788, Validation Loss: 0.2996\n",
      "Learning Rate: 0.0005, Epoch: 13, Train Loss: 0.2748, Validation Loss: 0.3011\n",
      "Learning Rate: 0.0005, Epoch: 14, Train Loss: 0.2734, Validation Loss: 0.2994\n",
      "Learning Rate: 0.0005, Epoch: 15, Train Loss: 0.2713, Validation Loss: 0.2989\n"
     ]
    }
   ],
   "source": [
    "# Paths for saving\n",
    "save_dir = \"models/alexnet\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Define Params\n",
    "criterion = nn.BCELoss()\n",
    "num_epochs = 15\n",
    "learning_rates = [0.001, 0.0005]\n",
    "\n",
    "# Track losses for visualization\n",
    "train_losses_dict = {}\n",
    "valid_losses_dict = {}\n",
    "\n",
    "# Iterate over different learning rates\n",
    "for lr in learning_rates:\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, alexnet.parameters()), lr=lr)\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "    train_losses = []  \n",
    "    valid_losses = []  \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        avg_train_loss = train(alexnet, train_loader, optimizer, criterion, device)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        valid_loss = evaluate(alexnet, valid_loader, criterion, device)\n",
    "        valid_losses.append(valid_loss)\n",
    "        \n",
    "        # Print validation loss\n",
    "        print(f'Learning Rate: {lr}, Epoch: {epoch+1}, Train Loss: {avg_train_loss:.4f}, Validation Loss: {valid_loss:.4f}')\n",
    "        \n",
    "        # Save the best model if validation loss improves\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(alexnet.state_dict(), os.path.join(save_dir, f'best_model_lr_{lr}.pt'))\n",
    "\n",
    "    # Store losses for visualization\n",
    "    train_losses_dict[lr] = train_losses\n",
    "    valid_losses_dict[lr] = valid_losses\n",
    "\n",
    "# Save losses dictionaries for visualization later\n",
    "torch.save(train_losses_dict, os.path.join(save_dir, 'train_losses.pt'))\n",
    "torch.save(valid_losses_dict, os.path.join(save_dir, 'valid_losses.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
